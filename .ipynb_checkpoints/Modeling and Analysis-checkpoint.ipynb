{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             classification_report, \n",
    "                             precision_score, recall_score, \n",
    "                             accuracy_score, f1_score)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('student_data.csv')\n",
    "data.drop('Unnamed: 0', axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, I'll be using 5 different targets. For each target, I will: \n",
    "1) build a model \n",
    "2) use that model to determine the factors that make a student most prone to be part of a specific class\n",
    "3) use that model to determine the factors that make a student's outcomes most likely to improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['X4EVERDROP', 'X4HSCOMPSTAT', 'X4REFSELECT', \n",
    "           'X4ATPRLVLA', 'X4PSLFSTFB16']\n",
    "X = data.drop(targets, axis= 1)\n",
    "drop_target = data['X4EVERDROP']\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, \n",
    " y_train, y_test) = train_test_split(X, drop_target, \n",
    "                                     test_size= .2, \n",
    "                                     random_state = 24)\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('\\nClassification Report\\n')\n",
    "    print(classification_report(y_test, y_pred))  \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= 'X4EVERDROP', data= data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1423  431]\n",
      " [  77  176]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85      1854\n",
      "           1       0.29      0.70      0.41       253\n",
      "\n",
      "    accuracy                           0.76      2107\n",
      "   macro avg       0.62      0.73      0.63      2107\n",
      "weighted avg       0.87      0.76      0.80      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver= 'liblinear', \n",
    "                            class_weight= 'balanced')\n",
    "log_pred = report(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1443  411]\n",
      " [  84  169]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85      1854\n",
      "           1       0.29      0.67      0.41       253\n",
      "\n",
      "    accuracy                           0.77      2107\n",
      "   macro avg       0.62      0.72      0.63      2107\n",
      "weighted avg       0.87      0.77      0.80      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_bag = BaggingClassifier(logreg, n_estimators = 20, \n",
    "                            max_samples = .8)\n",
    "log_bag_pred = report(log_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1730  124]\n",
      " [ 200   53]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      1854\n",
      "           1       0.30      0.21      0.25       253\n",
      "\n",
      "    accuracy                           0.85      2107\n",
      "   macro avg       0.60      0.57      0.58      2107\n",
      "weighted avg       0.82      0.85      0.83      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(weights= 'distance', \n",
    "                           n_neighbors= 2)\n",
    "knn_pred = report(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1460  394]\n",
      " [ 107  146]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85      1854\n",
      "           1       0.27      0.58      0.37       253\n",
      "\n",
      "    accuracy                           0.76      2107\n",
      "   macro avg       0.60      0.68      0.61      2107\n",
      "weighted avg       0.85      0.76      0.80      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb_pred = report(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1642  212]\n",
      " [ 157   96]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      1854\n",
      "           1       0.31      0.38      0.34       253\n",
      "\n",
      "    accuracy                           0.82      2107\n",
      "   macro avg       0.61      0.63      0.62      2107\n",
      "weighted avg       0.84      0.82      0.83      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree_pred = report(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1438  416]\n",
      " [  99  154]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85      1854\n",
      "           1       0.27      0.61      0.37       253\n",
      "\n",
      "    accuracy                           0.76      2107\n",
      "   macro avg       0.60      0.69      0.61      2107\n",
      "weighted avg       0.86      0.76      0.79      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'criterion':['gini', 'entropy'], \n",
    "          'splitter':['best', 'random'], \n",
    "          'max_depth':[10, 50, 100], \n",
    "          'min_samples_split':[2, 10, 20], \n",
    "          'class_weight':[None, 'balanced']}\n",
    "gs_tree= GridSearchCV(DecisionTreeClassifier(), params, cv=3, \n",
    "                      scoring= 'recall')\n",
    "gs_tree_pred = report(gs_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1501  353]\n",
      " [  96  157]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      1854\n",
      "           1       0.31      0.62      0.41       253\n",
      "\n",
      "    accuracy                           0.79      2107\n",
      "   macro avg       0.62      0.72      0.64      2107\n",
      "weighted avg       0.86      0.79      0.81      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(class_weight= 'balanced', \n",
    "                              max_depth= 2)\n",
    "tree_bag = (BaggingClassifier(tree))\n",
    "tree_bag_pred = report(tree_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1501  353]\n",
      " [  96  157]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      1854\n",
      "           1       0.31      0.62      0.41       253\n",
      "\n",
      "    accuracy                           0.79      2107\n",
      "   macro avg       0.62      0.72      0.64      2107\n",
      "weighted avg       0.86      0.79      0.81      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':[10, 100], \n",
    "          'max_features':[1.0, .9]}\n",
    "gs_tree_bag= GridSearchCV(tree_bag, params, cv=3, \n",
    "                      scoring= 'recall')\n",
    "gs_tree_bag_pred = report(gs_tree_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1824   30]\n",
      " [ 190   63]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      1854\n",
      "           1       0.68      0.25      0.36       253\n",
      "\n",
      "    accuracy                           0.90      2107\n",
      "   macro avg       0.79      0.62      0.65      2107\n",
      "weighted avg       0.88      0.90      0.87      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada_tree_pred = report(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1419  435]\n",
      " [  79  174]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85      1854\n",
      "           1       0.29      0.69      0.40       253\n",
      "\n",
      "    accuracy                           0.76      2107\n",
      "   macro avg       0.62      0.73      0.63      2107\n",
      "weighted avg       0.87      0.76      0.79      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(logreg)\n",
    "ada_log_pred = report(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1849    5]\n",
      " [ 241   12]]\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      1854\n",
      "           1       0.71      0.05      0.09       253\n",
      "\n",
      "    accuracy                           0.88      2107\n",
      "   macro avg       0.80      0.52      0.51      2107\n",
      "weighted avg       0.86      0.88      0.84      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(class_weight='balanced', \n",
    "                                     n_estimators= 100)\n",
    "rand_forest_pred = report(rand_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Ensemble\n",
    "I'll attempt to improve recall of the 'at-risk' class of students by taking the consensus of the three highest performing models by their ability to recall 'at-risk' students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1422  432]\n",
      " [  79  174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.77      0.85      1854\n",
      "           1       0.29      0.69      0.41       253\n",
      "\n",
      "    accuracy                           0.76      2107\n",
      "   macro avg       0.62      0.73      0.63      2107\n",
      "weighted avg       0.87      0.76      0.79      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(0, len(log_pred)):\n",
    "    preds.append(statistics.mode([log_pred[i], \n",
    "                                 ada_log_pred[i], \n",
    "                                  nb_pred[i]]))\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Because the goal of this tool would be to identify the students at risk of dropping out, while simaltaneously saving resources to be shared by all students, the models ability to recall dropouts is the primary concern. To that end, when adjusting the confidence level required by the model to classify a student, I found that we could improve recall to 81% by lowering the required confidence to .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6376 2902]\n",
      " [ 239 1015]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80      9278\n",
      "           1       0.26      0.81      0.39      1254\n",
      "\n",
      "    accuracy                           0.70     10532\n",
      "   macro avg       0.61      0.75      0.60     10532\n",
      "weighted avg       0.88      0.70      0.75     10532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = logreg.predict_proba(X)\n",
    "y_pred = []\n",
    "for prob in probs:\n",
    "    if prob[1]> .4:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "print(confusion_matrix(drop_target, y_pred))\n",
    "print(classification_report(drop_target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears, based on experimentation with a similar technique using the adaboost classifier, that even 49% confidence in a classification improves the recall score for dropouts significantly. However, this comes with a drastic reduction in recall for predicting students that stayed in school.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1596 7682]\n",
      " [  24 1230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.17      0.29      9278\n",
      "           1       0.14      0.98      0.24      1254\n",
      "\n",
      "    accuracy                           0.27     10532\n",
      "   macro avg       0.56      0.58      0.27     10532\n",
      "weighted avg       0.88      0.27      0.29     10532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = ada.predict_proba(X)\n",
    "y_pred = []\n",
    "for prob in probs:\n",
    "    if prob[1]> .49:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "print(confusion_matrix(drop_target, y_pred))\n",
    "print(classification_report(drop_target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The adaboost classifier used in conjuction with logistic regression modeling as its weak learner model is most successful at identifying the students that will eventually drop out of High School. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
